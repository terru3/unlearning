{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b4b5f20-1af9-4c76-9817-13a502b84e84",
   "metadata": {},
   "source": [
    "# Just-In-Time (JiT) Unlearning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb95043-53a1-4690-aaee-69299f3f93cf",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/2402.01401"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60093d5d-ab3b-48c4-9b4b-34b78d206a1d",
   "metadata": {},
   "source": [
    "### Zero-shot unlearning (*)\n",
    "*Disclaimer: This zero-shot unlearning technique defines zero-shot as having access to the forget data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb431cdd-1b90-4f18-80a0-743b8c62a9f0",
   "metadata": {},
   "source": [
    "## TODO: fix catastrophic unlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d8b9b82-cd89-4401-aa1d-a2ee01675e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import gc\n",
    "import json\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchinfo import summary\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b0b9e0b-32de-4c48-af05-08acddbd7a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "209e2728-6ead-40f7-96f0-1f2ef7646a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive = None\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7be4ef1-65d0-4d0a-8b3c-e54154f2f7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./\"\n",
    "sys.path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38a5a33d-7779-458d-a0bd-678e15f207e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "path = path if drive is None else \"/content/drive/MyDrive/self-learn/unlearning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bbbd3f0a-951f-442b-a838-82d0177bb616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import *\n",
    "from utils import set_seed, train_data, val_data, train_loader, val_loader, fine_labels\n",
    "from models import get_model_and_optimizer\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f295fa22-3134-4c48-a717-106da164bb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: CNN_CIFAR_100_ORIGINAL\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = f\"CNN_CIFAR_100_ORIGINAL\"\n",
    "print(\"Model Name:\", MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbaed7e-f154-4f09-9dc7-23d984921c83",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "764328cc-4458-4879-9c19-88caad82698a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cloud'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_class = 23\n",
    "fine_labels[target_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78e85115-1540-438a-b44d-f02d47a979a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, val_loader, criterion, device):\n",
    "    val_losses = []\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (img, label) in enumerate(val_loader):\n",
    "\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            out = model(img)  # model returns activations as well\n",
    "            loss_eval = criterion(out, label)\n",
    "            val_losses.append(loss_eval.item())\n",
    "\n",
    "            pred = out.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "\n",
    "    val_loss = np.mean(val_losses)\n",
    "    val_acc = correct / ((len(val_loader) - 1) * BATCH_SIZE + label.size(0))\n",
    "\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a105a27-a151-42ca-83b7-4b681167763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "forget_idx = np.where(np.array(train_data.targets) == target_class)[0]\n",
    "forget_mask = np.zeros(len(train_data.targets), dtype=bool)\n",
    "forget_mask[forget_idx] = True\n",
    "retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
    "\n",
    "forget_data = torch.utils.data.Subset(train_data, forget_idx)\n",
    "retain_data = torch.utils.data.Subset(train_data, retain_idx)\n",
    "\n",
    "forget_loader = torch.utils.data.DataLoader(\n",
    "    forget_data, batch_size=BATCH_SIZE, shuffle=False\n",
    ")\n",
    "retain_loader = torch.utils.data.DataLoader(\n",
    "    retain_data, batch_size=BATCH_SIZE, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3bf986-ce68-4ba8-a4a7-ee32546d2cc3",
   "metadata": {},
   "source": [
    "# JiT Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b3e3283-c099-49fd-a6a5-e4ec6561eba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic idea:\n",
    "\n",
    "# Create randomly perturbed variants of forget set via additive noise\n",
    "# Train model to minimize output distance between original forget set and this perturbed set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f240999-ac41-48ac-a444-b505105ca0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise(object):\n",
    "    def __init__(self, mean=0.0, std=1.0, device=\"cpu\"):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        _max = tensor.max()\n",
    "        _min = tensor.min()\n",
    "        tensor = (\n",
    "            tensor + torch.randn_like(tensor).to(self.device) * self.std + self.mean\n",
    "        )\n",
    "        tensor = torch.clamp(tensor, min=_min, max=_max)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d215358-c98d-451e-8d10-d35aec1018b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_fn = transforms.Compose(\n",
    "    [\n",
    "        GaussianNoise(0.0, SIGMA, device=device),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5955c397-68be-44b1-bf18-770a3017641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jit_train(model, forget_loader, optimizer, criterion, device):\n",
    "\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    train_losses = []\n",
    "\n",
    "    for step, (img, label) in enumerate(forget_loader):\n",
    "        img, label = img.to(device), label.to(device)\n",
    "\n",
    "        # or no?\n",
    "        # optimizer.zero_grad()\n",
    "        \n",
    "        out = model(img)\n",
    "        loss = torch.tensor(0., device=device)\n",
    "        for _ in range(N_VARIANT):\n",
    "            # apply transform_fn\n",
    "            var_img = transform_fn(img)\n",
    "            \n",
    "            # pass to model via no.grad\n",
    "            with torch.no_grad():\n",
    "                var_out = model(var_img)\n",
    "\n",
    "            in_norm = torch.linalg.vector_norm(img - var_img, dim=(1,2,3))\n",
    "            out_norm = torch.linalg.vector_norm(out - var_out, dim=(1,))\n",
    "            \n",
    "            k =  (out_norm / in_norm).mean()\n",
    "            # take average of k over the batch size, finite-sample Monte-Carlo estimate\n",
    "            loss += k\n",
    "\n",
    "        loss /= N_VARIANT\n",
    "        train_losses.append(loss.item())\n",
    "        loss.backward()\n",
    "\n",
    "        grads = [\n",
    "            param.grad.detach().flatten()\n",
    "            for param in model.parameters()\n",
    "            if param.grad is not None\n",
    "        ]\n",
    "        norm = torch.cat(grads).norm()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % 5 == 0:\n",
    "            print(\n",
    "                  f\"Step: {step}/{len(forget_loader)}, Running Average Loss: {np.mean(train_losses):.3f} |\",\n",
    "                  f\"Grad Norm: {norm:.2f}\"\n",
    "                )\n",
    "\n",
    "        if step == MAX_STEPS - 1:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3def29fd-a3cb-48d5-adf9-70d3d3069d7c",
   "metadata": {},
   "source": [
    "# Driver code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f3835c3e-ee66-4c7f-be88-be568f544412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "LOAD_EPOCH = 100\n",
    "\n",
    "model, _ = get_model_and_optimizer()\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        f\"{path}/checkpoints/{MODEL_NAME}_EPOCH_{LOAD_EPOCH}_SEED_{SEED}.pt\",\n",
    "        map_location=device,\n",
    "    )[\"model_state_dict\"]\n",
    ")\n",
    "model.to(device)\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "21918ade-53eb-4a1d-b0d5-b46c00adf31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8b79cb9b-1526-42f5-af69-d28ffd049e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=JIT_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0acaab04-f3a9-47de-ae45-dd13ba29f392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0/63, Running Average Loss: 1.323 | Grad Norm: 8.56\n",
      "Step: 5/63, Running Average Loss: 1.241 | Grad Norm: 24.64\n"
     ]
    }
   ],
   "source": [
    "########### Driver code\n",
    "jit_train(model, forget_loader, optimizer, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "91372ae6-b5b9-447f-bdc0-b0d2687db9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08, 0.1238)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forget and val data accuracy\n",
    "eval(model, forget_loader, criterion, device)[1], eval(model, val_loader, criterion, device)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2301209d-135d-4997-b507-34b8ee8e94c9",
   "metadata": {},
   "source": [
    "## TODO: Fix catastrophic unlearning (e.g. 5% forget, 15% val)\n",
    "    -if we set zero_grad() on our optimizer (not recommended), forget stays around 10-15% while val degrades to similar numbers\n",
    "\n",
    "#### training log notes:\n",
    "    -gradient norms tend to be quite unstable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6cedf83-ace7-4c0d-8023-7dbbca6e20a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q: What is the intuition behind not setting our unlearning optimizer to zero_grad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf45401-2500-4c1b-bdde-ecb9dc62899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(\n",
    "#             {\n",
    "#                 \"model_state_dict\": model.state_dict(),\n",
    "#             },\n",
    "#             f\"{path}/checkpoints/{MODEL_NAME}_UNLEARNED_JIT.pt\"\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c500f2-98db-4407-8e55-e82782ae5788",
   "metadata": {},
   "source": [
    "## visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "51e852dd-9b41-4358-b2ad-fcf6307693ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use shuffle for more interesting results\n",
    "val_viz_loader = torch.utils.data.DataLoader(\n",
    "    val_data, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "forget_viz_loader = torch.utils.data.DataLoader(\n",
    "    forget_data, batch_size=BATCH_SIZE, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3798b0f4-55e1-47b0-967d-50331fd95616",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # choose one batch from val and one batch from forget\n",
    "    for (val_img, val_label), (forget_img, forget_label) in zip(\n",
    "        val_viz_loader, forget_viz_loader\n",
    "    ):\n",
    "        viz_img, viz_label = torch.cat([val_img, forget_img]), torch.cat(\n",
    "            [val_label, forget_label]\n",
    "        )\n",
    "        viz_img, viz_label = viz_img.to(device), viz_label.to(device)\n",
    "        out = model(viz_img)\n",
    "        pred = out.argmax(dim=-1)\n",
    "        break\n",
    "\n",
    "# assumes BATCH_SIZE=8\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16, 12))\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    ax.set_title(\n",
    "        f\"Pred: {fine_labels[pred[i]]} | Label: {fine_labels[viz_label[i]]}\", fontsize=8\n",
    "    )\n",
    "    ax.imshow(invTrans(viz_img[i]).cpu().permute(1, 2, 0))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
