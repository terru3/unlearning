{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b4b5f20-1af9-4c76-9817-13a502b84e84",
   "metadata": {},
   "source": [
    "# Gated Knowledge Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb95043-53a1-4690-aaee-69299f3f93cf",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/2201.05629"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aadc21-7469-4cd0-a8f8-e65de252c78f",
   "metadata": {},
   "source": [
    "### Remark: This notebook (GKT) may be archived soon——the student model is unable to learn much at all. This could potentially be due to sensitivity in hyperparameters, insufficient unlearning, a weak/small trained model vs. too strong of a generator, or simply errors in the code. Attempted fixes are in progress."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60093d5d-ab3b-48c4-9b4b-34b78d206a1d",
   "metadata": {},
   "source": [
    "### Zero-shot unlearning\n",
    "Note that access to any of the data whatsoever is not required in this post-hoc unlearning technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d8b9b82-cd89-4401-aa1d-a2ee01675e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import gc\n",
    "import json\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchinfo import summary\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "209e2728-6ead-40f7-96f0-1f2ef7646a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive = None\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7be4ef1-65d0-4d0a-8b3c-e54154f2f7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./\"\n",
    "sys.path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38a5a33d-7779-458d-a0bd-678e15f207e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "path = path if drive is None else \"/content/drive/MyDrive/self-learn/unlearning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbbd3f0a-951f-442b-a838-82d0177bb616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from constants import *\n",
    "from utils import set_seed, train_data, val_data, train_loader, val_loader, fine_labels\n",
    "from models import get_model_and_optimizer\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f295fa22-3134-4c48-a717-106da164bb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: CNN_CIFAR_100_ORIGINAL\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = f\"CNN_CIFAR_100_ORIGINAL\"\n",
    "print(\"Model Name:\", MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbaed7e-f154-4f09-9dc7-23d984921c83",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "764328cc-4458-4879-9c19-88caad82698a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cloud'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_class = 23\n",
    "fine_labels[target_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78e85115-1540-438a-b44d-f02d47a979a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, val_loader, criterion, device):\n",
    "    val_losses = []\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (img, label) in enumerate(val_loader):\n",
    "\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            out, _ = model(img)  # model returns activations as well\n",
    "            loss_eval = criterion(out, label)\n",
    "            val_losses.append(loss_eval.item())\n",
    "\n",
    "            pred = out.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "\n",
    "    val_loss = np.mean(val_losses)\n",
    "    val_acc = correct / ((len(val_loader) - 1) * BATCH_SIZE + label.size(0))\n",
    "\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a105a27-a151-42ca-83b7-4b681167763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "forget_idx = np.where(np.array(train_data.targets) == target_class)[0]\n",
    "forget_mask = np.zeros(len(train_data.targets), dtype=bool)\n",
    "forget_mask[forget_idx] = True\n",
    "retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
    "\n",
    "forget_data = torch.utils.data.Subset(train_data, forget_idx)\n",
    "retain_data = torch.utils.data.Subset(train_data, retain_idx)\n",
    "\n",
    "forget_loader = torch.utils.data.DataLoader(\n",
    "    forget_data, batch_size=BATCH_SIZE, shuffle=False\n",
    ")\n",
    "retain_loader = torch.utils.data.DataLoader(\n",
    "    retain_data, batch_size=BATCH_SIZE, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3bf986-ce68-4ba8-a4a7-ee32546d2cc3",
   "metadata": {},
   "source": [
    "# GKT Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b3e3283-c099-49fd-a6a5-e4ec6561eba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## General pseudocode idea:\n",
    "\n",
    "## Load trained model as teacher, student as random, define generator class and instantiate\n",
    "\n",
    "## train generator:\n",
    "## Create random noise z:\n",
    "## pass z to generator to create pseudo sample x. Pass through band-pass filter,\n",
    "## then compute negative KL divergence of T(x) || S(x) to update generator to maximize distance. End\n",
    "\n",
    "## train student:\n",
    "## train student—sample from generator pseudo samples (filter alr applied)\n",
    "## use student loss function (KL divergence + β (HP) * L_{at}) to update student to minimize distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0f195ee-791d-4aab-b8f8-19c5099cf8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## copied directly from repo\n",
    "def attention(x):\n",
    "    \"\"\"\n",
    "    Taken from https://github.com/szagoruyko/attention-transfer\n",
    "    :param x = activations\n",
    "    \"\"\"\n",
    "    return F.normalize(x.pow(2).mean(1).view(x.size(0), -1))  # B, -1\n",
    "\n",
    "\n",
    "def attention_diff(x, y):\n",
    "    \"\"\"\n",
    "    Taken from https://github.com/szagoruyko/attention-transfer\n",
    "    :param x = activations\n",
    "    :param y = activations\n",
    "    \"\"\"\n",
    "    return (attention(x) - attention(y)).pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0e15ea3-a7c1-4e0e-a1c5-52a2b3cf88dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(st_logits, t_logits):\n",
    "\n",
    "    t_probs = F.softmax(t_logits, dim=-1)\n",
    "    st_log_probs = F.log_softmax(\n",
    "        st_logits, dim=-1\n",
    "    )  # F.kl_div expects log softmax in first arg\n",
    "    return -F.kl_div(st_log_probs, t_probs, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f31b8a0c-95f9-4c15-bfa8-3e07485d8324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gkt_loss(st_logits, t_logits, st_act, t_act):\n",
    "\n",
    "    t_probs = F.softmax(t_logits, dim=-1)\n",
    "    st_log_probs = F.log_softmax(\n",
    "        st_logits, dim=-1\n",
    "    )  # F.kl_div expects log softmax in first arg\n",
    "    kl_div = F.kl_div(st_log_probs, t_probs, reduction=\"mean\")\n",
    "\n",
    "    attn_loss = 0\n",
    "    for i in range(len(st_act)):\n",
    "        attn_loss += ATTN_BETA * attention_diff(st_act[i], t_act[i])\n",
    "\n",
    "    return kl_div + attn_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb066d27-1c5e-4bd9-8aa0-2265d4284a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: move into models.py, e.g. via get_gen or get_gen_and_optimizer\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                Z_DIM, 128, kernel_size=6, stride=1, padding=1, bias=False\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ConvTranspose2d(16, 3, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.net(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8ab2061-eef7-4f41-912f-3b82311f4c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gkt_train(gen, st_model, t_model, gen_optimizer, st_optimizer, device):\n",
    "    gen.train()\n",
    "    t_model.eval()\n",
    "\n",
    "    gen_train_losses, unlearn_losses = [], []\n",
    "    filter_pct = []\n",
    "\n",
    "    # for every single pseudo_batch, take 1 gen step then n student steps\n",
    "    # so fake is generated (n+1) * PSEUDO_BATCHES times in total, and the noise used for fake\n",
    "    # is re-created every pseudo_batch\n",
    "    for batch_step in range(PSEUDO_BATCHES):\n",
    "        z = torch.randn(BATCH_SIZE, Z_DIM, 1, 1).to(device)\n",
    "        for step in range(STUDENT_PER_GEN_STEPS + 1):\n",
    "            fake = gen(z).to(device)\n",
    "            with torch.no_grad():\n",
    "                fake_preds, _ = t_model(fake)\n",
    "            mask = torch.softmax(fake_preds, dim=1)[:, target_class] < BAND_PASS_THRESH\n",
    "            x_pseudo = fake[mask]\n",
    "            filter_pct.append((x_pseudo.size(0) / BATCH_SIZE) * 100)\n",
    "            if x_pseudo.size(0) == 0:\n",
    "                continue\n",
    "\n",
    "            # train generator\n",
    "            if step == 0:\n",
    "                st_model.eval()\n",
    "                gen_optimizer.zero_grad()\n",
    "                st_logits, _ = st_model(x_pseudo)\n",
    "                t_logits, _ = t_model(x_pseudo)\n",
    "                loss = generator_loss(st_logits, t_logits)\n",
    "                loss.backward()\n",
    "                gen_train_losses.append(loss.item())\n",
    "                gen_optimizer.step()\n",
    "\n",
    "            # train student\n",
    "            else:\n",
    "                st_model.train()\n",
    "                with torch.no_grad():\n",
    "                    t_logits, t_act = t_model(x_pseudo)\n",
    "\n",
    "                st_optimizer.zero_grad()\n",
    "                st_logits, st_act = st_model(x_pseudo)\n",
    "                loss = gkt_loss(st_logits, t_logits, st_act, t_act)\n",
    "                loss.backward()\n",
    "                unlearn_losses.append(loss.item())\n",
    "                st_optimizer.step()\n",
    "\n",
    "        if batch_step % 50 == 0:\n",
    "            print(\n",
    "                f\"Batch step {batch_step}/{PSEUDO_BATCHES} | Running Gen Loss: {np.mean(gen_train_losses):.4f} |\",\n",
    "                f\"Running Unlearn Loss: {np.mean(unlearn_losses):.4f} | {np.mean(filter_pct):.2f}% samples passed the filter\",\n",
    "            )\n",
    "\n",
    "        if batch_step % 100 == 0:\n",
    "            print(\"Evaluating model\")\n",
    "            print(\n",
    "                f\"Forget Acc: {eval(st_model, forget_loader, criterion, device)[1]} |\",\n",
    "                f\"Retain Acc: {eval(st_model, retain_subset_loader, criterion, device)[1]}\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3def29fd-a3cb-48d5-adf9-70d3d3069d7c",
   "metadata": {},
   "source": [
    "# Driver code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3835c3e-ee66-4c7f-be88-be568f544412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher model loaded\n"
     ]
    }
   ],
   "source": [
    "LOAD_EPOCH = 100\n",
    "\n",
    "t_model, _ = get_model_and_optimizer(return_act=True)\n",
    "t_model.load_state_dict(\n",
    "    torch.load(\n",
    "        f\"{path}/checkpoints/{MODEL_NAME}_EPOCH_{LOAD_EPOCH}_SEED_{SEED}.pt\",\n",
    "        map_location=device,\n",
    "    )[\"model_state_dict\"]\n",
    ")\n",
    "t_model.to(device)\n",
    "print(\"Teacher model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21918ade-53eb-4a1d-b0d5-b46c00adf31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd7c1e67-587a-4fc8-880d-b0a121733994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model initialized\n"
     ]
    }
   ],
   "source": [
    "# initialize student as random\n",
    "st_model, st_optimizer = get_model_and_optimizer(return_act=True, seed=SEED)\n",
    "st_model.to(device)\n",
    "print(\"Student model initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d58766e-ee4f-474b-86b4-d45cefe5aad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_idx = list(range(0, len(retain_data), 25))  ### change back to 10 later\n",
    "retain_data_subset = torch.utils.data.Subset(retain_data, subset_idx)\n",
    "retain_subset_loader = torch.utils.data.DataLoader(\n",
    "    retain_data_subset, batch_size=BATCH_SIZE, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80101261-a2b6-48b5-b8b9-98e367b6774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## archived plain knowledge distillation on retain data\n",
    "\n",
    "# T = 2\n",
    "# DISTILLATION_STEPS = 1000\n",
    "\n",
    "# t_model.eval()\n",
    "# st_model.train()\n",
    "# distillation_losses = []\n",
    "# for step, (img, label) in enumerate(retain_subset_loader):\n",
    "#     img, label = img.to(device), label.to(device)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         t_logits, t_act = t_model(z)\n",
    "\n",
    "#     st_optimizer.zero_grad()\n",
    "#     st_logits, st_act = st_model(z)\n",
    "\n",
    "#     t_probs = F.softmax(t_logits, dim=-1)\n",
    "#     st_log_probs = F.log_softmax(st_logits, dim=-1) # F.kl_div expects log softmax in first arg\n",
    "#     loss = F.kl_div(st_log_probs, t_probs, reduction='mean')\n",
    "\n",
    "#     ### from pytorch tutorial on distillation\n",
    "#     # t_probs = F.softmax(t_logits / T, dim=-1)\n",
    "#     # st_log_probs = F.log_softmax(st_logits / T, dim=-1)\n",
    "#     # loss = -torch.sum(t_probs * st_log_probs) / st_log_probs.size()[0] * (T**2)\n",
    "\n",
    "#     loss.backward()\n",
    "#     distillation_losses.append(loss.item())\n",
    "#     st_optimizer.step()\n",
    "\n",
    "#     if step % 20 == 0:\n",
    "#         print(f\"Step: {step}/{len(retain_subset_loader)}, Running Distillation Loss: {np.mean(distillation_losses):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0494ef-2f5e-4347-8c2c-78dc80b4bf4f",
   "metadata": {},
   "source": [
    "# –––––––––––––––––"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "43305d6d-676f-4118-a815-e54ccd578f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.00909090909090909)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### prior to GKT——student = randomly initialized\n",
    "\n",
    "# forget and retain data accuracy\n",
    "eval(st_model, forget_loader, criterion, device)[1], eval(\n",
    "    st_model, retain_subset_loader, criterion, device\n",
    ")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95af2dc8-8160-4138-a274-d54dee269e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize generator\n",
    "set_seed()\n",
    "gen = Generator().to(device)\n",
    "gen_optimizer = torch.optim.AdamW(gen.parameters(), lr=GEN_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8dddf17-c45c-4218-a4f8-2ade5cbec0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Terru/opt/miniconda3/envs/unlearning/lib/python3.11/site-packages/torch/nn/functional.py:2943: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch step 0/4000 | Running Gen Loss: -0.0373 | Running Unlearn Loss: 0.1242 | 100.00% samples passed the filter\n",
      "Evaluating model\n",
      "Forget Acc: 0.0 | Retain Acc: 0.00909090909090909\n",
      "Batch step 50/4000 | Running Gen Loss: -0.0242 | Running Unlearn Loss: 0.1015 | 92.22% samples passed the filter\n",
      "Batch step 100/4000 | Running Gen Loss: -0.0151 | Running Unlearn Loss: 0.0949 | 91.66% samples passed the filter\n",
      "Evaluating model\n",
      "Forget Acc: 0.0 | Retain Acc: 0.009595959595959595\n",
      "Batch step 150/4000 | Running Gen Loss: -0.0123 | Running Unlearn Loss: 0.0941 | 92.96% samples passed the filter\n",
      "Batch step 200/4000 | Running Gen Loss: -0.0111 | Running Unlearn Loss: 0.0916 | 94.47% samples passed the filter\n",
      "Evaluating model\n",
      "Forget Acc: 0.0 | Retain Acc: 0.011616161616161616\n",
      "Batch step 250/4000 | Running Gen Loss: -0.0114 | Running Unlearn Loss: 0.0884 | 95.47% samples passed the filter\n",
      "Batch step 300/4000 | Running Gen Loss: -0.0117 | Running Unlearn Loss: 0.0831 | 96.22% samples passed the filter\n",
      "Evaluating model\n",
      "Forget Acc: 0.0 | Retain Acc: 0.00909090909090909\n",
      "Batch step 350/4000 | Running Gen Loss: -0.0202 | Running Unlearn Loss: 0.0802 | 96.48% samples passed the filter\n",
      "Batch step 400/4000 | Running Gen Loss: -0.0601 | Running Unlearn Loss: 0.0785 | 96.76% samples passed the filter\n",
      "Evaluating model\n",
      "Forget Acc: 0.0 | Retain Acc: 0.014141414141414142\n",
      "Batch step 450/4000 | Running Gen Loss: -0.0911 | Running Unlearn Loss: 0.0787 | 96.98% samples passed the filter\n",
      "Batch step 500/4000 | Running Gen Loss: -0.1159 | Running Unlearn Loss: 0.0771 | 97.16% samples passed the filter\n",
      "Evaluating model\n",
      "Forget Acc: 0.0 | Retain Acc: 0.008585858585858586\n",
      "Batch step 550/4000 | Running Gen Loss: -0.1521 | Running Unlearn Loss: 0.0760 | 97.05% samples passed the filter\n",
      "Batch step 600/4000 | Running Gen Loss: -0.1526 | Running Unlearn Loss: 0.0750 | 97.02% samples passed the filter\n",
      "Evaluating model\n",
      "Forget Acc: 0.0 | Retain Acc: 0.02070707070707071\n",
      "Batch step 650/4000 | Running Gen Loss: -0.1826 | Running Unlearn Loss: 0.0727 | 97.08% samples passed the filter\n",
      "Batch step 700/4000 | Running Gen Loss: -0.1745 | Running Unlearn Loss: 0.0701 | 97.18% samples passed the filter\n",
      "Evaluating model\n",
      "Forget Acc: 0.0 | Retain Acc: 0.01717171717171717\n",
      "Batch step 750/4000 | Running Gen Loss: -0.1775 | Running Unlearn Loss: 0.0678 | 97.29% samples passed the filter\n",
      "Batch step 800/4000 | Running Gen Loss: -0.1713 | Running Unlearn Loss: 0.0656 | 97.41% samples passed the filter\n",
      "Evaluating model\n",
      "Forget Acc: 0.0 | Retain Acc: 0.018686868686868686\n",
      "Batch step 850/4000 | Running Gen Loss: -0.1713 | Running Unlearn Loss: 0.0637 | 97.53% samples passed the filter\n",
      "Batch step 900/4000 | Running Gen Loss: -0.1753 | Running Unlearn Loss: 0.0621 | 97.67% samples passed the filter\n",
      "Evaluating model\n",
      "Forget Acc: 0.0 | Retain Acc: 0.020202020202020204\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m######################## Driver code\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mgkt_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mst_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mst_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 38\u001b[0m, in \u001b[0;36mgkt_train\u001b[0;34m(gen, st_model, t_model, gen_optimizer, st_optimizer, device)\u001b[0m\n\u001b[1;32m     36\u001b[0m st_model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 38\u001b[0m     t_logits, t_act \u001b[38;5;241m=\u001b[39m \u001b[43mt_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_pseudo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m st_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     41\u001b[0m st_logits, st_act \u001b[38;5;241m=\u001b[39m st_model(x_pseudo)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/unlearning/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/unlearning/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/self-learn/unlearning/models.py:70\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     68\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmax_pool2d(x, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 70\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m act4 \u001b[38;5;241m=\u001b[39m x  \u001b[38;5;66;03m# (BATCH_SIZE, 512, 4, 4)\u001b[39;00m\n\u001b[1;32m     72\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/unlearning/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/unlearning/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/unlearning/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/unlearning/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "######################## Driver code\n",
    "gkt_train(gen, st_model, t_model, gen_optimizer, st_optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04fe94ea-2a83-47a9-8227-927ba0232960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.014646464646464647)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### after GKT\n",
    "\n",
    "# forget and val data accuracy\n",
    "eval(st_model, forget_loader, criterion, device)[1], eval(\n",
    "    st_model, retain_subset_loader, criterion, device\n",
    ")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf45401-2500-4c1b-bdde-ecb9dc62899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(\n",
    "#             {\n",
    "#                 \"model_state_dict\": model.state_dict(),\n",
    "#             },\n",
    "#             f\"{path}/checkpoints/{MODEL_NAME}_UNLEARNED_GKT.pt\"\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c500f2-98db-4407-8e55-e82782ae5788",
   "metadata": {},
   "source": [
    "## visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "51e852dd-9b41-4358-b2ad-fcf6307693ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use shuffle for more interesting results\n",
    "val_viz_loader = torch.utils.data.DataLoader(\n",
    "    val_data, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "forget_viz_loader = torch.utils.data.DataLoader(\n",
    "    forget_data, batch_size=BATCH_SIZE, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3798b0f4-55e1-47b0-967d-50331fd95616",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # choose one batch from val and one batch from forget\n",
    "    for (val_img, val_label), (forget_img, forget_label) in zip(\n",
    "        val_viz_loader, forget_viz_loader\n",
    "    ):\n",
    "        viz_img, viz_label = torch.cat([val_img, forget_img]), torch.cat(\n",
    "            [val_label, forget_label]\n",
    "        )\n",
    "        viz_img, viz_label = viz_img.to(device), viz_label.to(device)\n",
    "        out = model(viz_img)\n",
    "        pred = out.argmax(dim=-1)\n",
    "        break\n",
    "\n",
    "# assumes BATCH_SIZE=8\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16, 12))\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    ax.set_title(\n",
    "        f\"Pred: {fine_labels[pred[i]]} | Label: {fine_labels[viz_label[i]]}\", fontsize=8\n",
    "    )\n",
    "    ax.imshow(invTrans(viz_img[i]).cpu().permute(1, 2, 0))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
