{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b4b5f20-1af9-4c76-9817-13a502b84e84",
   "metadata": {},
   "source": [
    "# Incompetent Teacher Unlearning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb95043-53a1-4690-aaee-69299f3f93cf",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/2205.08096 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1891eb4f-21f5-4851-a46b-23bdc1807d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchinfo import summary\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3542643-29bd-43eb-a6d8-85e647092884",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive = None\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00938151-9630-4a3d-8d1c-1c5b77bd8483",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./\"\n",
    "sys.path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ec7b014-35f6-4a0f-8b2c-8f5989b9ffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "path = path if drive is None else \"/content/drive/MyDrive/self-learn/unlearning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aafaf74-c71c-4d1b-9103-d401d981f3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from constants import *\n",
    "from utils import set_seed, train_data, val_data, \\\n",
    "                    train_loader, val_loader, fine_labels\n",
    "from models import get_model, get_attack_model\n",
    "    \n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "397817f9-c393-40ff-b980-0d80a17b703d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: CNN_CIFAR_100_ORIGINAL\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = (\n",
    "    f\"CNN_CIFAR_100_ORIGINAL\"\n",
    ")\n",
    "print(\"Model Name:\", MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e04356c-7f4b-4d26-a1b3-55f00dd73b62",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "498ee392-5bae-4962-b62f-c5512441fe68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cloud'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_class = 23\n",
    "fine_labels[target_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac0f139f-5416-4880-884f-9fb640988176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, val_loader, criterion, device):\n",
    "    val_losses = []\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (img, label) in enumerate(val_loader):\n",
    "          \n",
    "            img, label = img.to(device), label.to(device)\n",
    "            out = model(img)\n",
    "            \n",
    "            loss_eval = criterion(out, label)\n",
    "            val_losses.append(loss_eval.item())\n",
    "            \n",
    "            pred = out.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "\n",
    "    val_loss = np.mean(val_losses)\n",
    "    val_acc = correct / (len(val_loader) * BATCH_SIZE)\n",
    "    \n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9ed7f25-0042-4b57-beec-ba590b73a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "forget_idx = np.where(np.array(train_data.targets) == target_class)[0]\n",
    "forget_mask = np.zeros(len(train_data.targets), dtype=bool)\n",
    "forget_mask[forget_idx] = True\n",
    "retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
    "\n",
    "forget_data = torch.utils.data.Subset(train_data, forget_idx)\n",
    "retain_data = torch.utils.data.Subset(train_data, retain_idx)\n",
    "\n",
    "forget_loader = torch.utils.data.DataLoader(forget_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "retain_loader = torch.utils.data.DataLoader(retain_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77993e88-7e02-4b4e-99e5-53ad0c76fae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and optimizer loaded\n"
     ]
    }
   ],
   "source": [
    "LOAD_EPOCH = 50\n",
    "\n",
    "ct_model, ct_optimizer = get_model()\n",
    "ct_model.load_state_dict(torch.load(f\"{path}/checkpoints/{MODEL_NAME}_EPOCH_{LOAD_EPOCH}_SEED_{SEED}.pt\",\n",
    "                                  map_location=device)[\"model_state_dict\"])\n",
    "ct_optimizer.load_state_dict(torch.load(f\"{path}/checkpoints/{MODEL_NAME}_EPOCH_{LOAD_EPOCH}_SEED_{SEED}.pt\",\n",
    "                                  map_location=device)[\"optimizer_state_dict\"])\n",
    "ct_model.to(device)\n",
    "print('Model and optimizer loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd90f08d-46fd-453b-b98a-c8bcda8f89b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9df370f-f65f-41e0-b3db-a7dbeea4871f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize student\n",
    "st_model, st_optimizer = get_model()\n",
    "st_model.load_state_dict(ct_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f6fc2f1-0ec7-4d02-b96c-04954b0378a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize incompetent teacher\n",
    "it_model, it_optimizer = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2a0be7-d95c-4b2b-a0d0-c0d56a28abce",
   "metadata": {},
   "source": [
    "# ––––––––"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ffb1857a-89da-4e1a-b84b-510efeeb2a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unlearn_loss(st_logits, ct_logits, it_logits, labels):\n",
    "    \n",
    "    ct_probs, it_probs = F.softmax(ct_logits, dim=-1), F.softmax(it_logits, dim=-1)\n",
    "    # assuming 1 = forget\n",
    "    teacher_out = labels * it_probs + (1-labels) * ct_probs\n",
    "    st_log_probs = F.log_softmax(st_logits, dim=-1) # F.kl_div expects log softmax in first arg\n",
    "    return F.kl_div(st_log_probs, teacher_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "05343c3b-b32a-4f05-98b4-27cbfb925aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def JSDiv(model_1_logits, model_2_logits):\n",
    "    model_1_probs, model_2_probs = F.softmax(model_1_logits, dim=-1), F.softmax(model_2_logits, dim=-1)\n",
    "    m = (model_1_probs + model_2_probs) / 2\n",
    "    return (F.kl_div(torch.log(model_1_probs), m) + F.kl_div(torch.log(model_2_probs), m)) / 2\n",
    "\n",
    "def ZRF(model_1, model_2, forget_loader):\n",
    "    model_1, model_2 = model_1.to(device), model_2.to(device)\n",
    "    model_1_logits, model_2_logits = [], []\n",
    "    with torch.no_grad():\n",
    "        for i, (img, label) in enumerate(forget_loader):\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            model_1_logits.append(model_1(img).detach().cpu())\n",
    "            model_2_logits.append(model_2(img).detach().cpu())\n",
    "            \n",
    "    model_1_logits = torch.cat(model_1_logits, dim=0)\n",
    "    model_2_logits = torch.cat(model_2_logits, dim=0)\n",
    "    return 1 - (JSDiv(model_1_logits, model_2_logits) / len(forget_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "75ad9a1b-f22b-4fb9-a4f9-702cc9317915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9776)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9996)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not sure if these numbers make sense. I think maybe?, but a little too close to 1 for my liking\n",
    "# I added the division by len(forget_loader) because it appears in the original formula in the paper\n",
    "ZRF(ct_model, it_model, forget_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b095c63e-6e30-4a83-b88a-efd716bfaa62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9914)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9999)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not sure if these numbers make sense, to-validate\n",
    "ZRF(st_model, it_model, forget_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0a16c2-5755-406e-ad36-80ad17134eff",
   "metadata": {},
   "source": [
    "# in-progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e77e022-6385-4c2e-9e84-2cf78c128ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO:\n",
    "\n",
    "\n",
    "## Train as usual a competent teacher on the whole dataset, and initialize a student using its params\n",
    "## Create incompetent teacher via randomly initialized params\n",
    "\n",
    "## use unlearn loss to train student\n",
    "## for comparison, train a model entirely on retrain and see what accuracies / ZRF it achieves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0761f83-802e-46dc-a35d-44f863645f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unlearn(st_model, ct_model, it_model, train_loader, st_optimizer, unlearn_loss, device):\n",
    "    ct_model.to(device)\n",
    "    ct_model.eval()\n",
    "    it_model.to(device)\n",
    "    it_model.eval()\n",
    "    st_model.to(device)\n",
    "    st_model.train()\n",
    "    unlearn_losses = []\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "        for step, (img, label) in enumerate(train_loader):\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            st_optimizer.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                ct_logits = ct_model(img)\n",
    "                it_logits = it_model(img)\n",
    "            st_logits = model(x)\n",
    "            loss = unlearn_loss(st_logits, ct_logits, it_logits, labels=label)\n",
    "            unlearn_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            st_optimizer.step()\n",
    "        print(f\"Running Average Unlearn Loss: {np.mean(unlearn_losses):.3f}\")\n",
    "    return unlearn_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a505e709-0147-49ba-ac8f-e893fd884749",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlearn_losses = unlearn(st_model, ct_model, it_model, train_loader, st_optimizer, unlearn_loss, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
