{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b4b5f20-1af9-4c76-9817-13a502b84e84",
   "metadata": {},
   "source": [
    "# Just-In-Time (JiT) Unlearning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb95043-53a1-4690-aaee-69299f3f93cf",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/2402.01401"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60093d5d-ab3b-48c4-9b4b-34b78d206a1d",
   "metadata": {},
   "source": [
    "### Zero-shot unlearning (*)\n",
    "*Disclaimer: This zero-shot unlearning technique defines zero-shot as having access to the forget data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d8b9b82-cd89-4401-aa1d-a2ee01675e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import gc\n",
    "import json\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchinfo import summary\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "209e2728-6ead-40f7-96f0-1f2ef7646a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive = None\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7be4ef1-65d0-4d0a-8b3c-e54154f2f7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./\"\n",
    "sys.path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38a5a33d-7779-458d-a0bd-678e15f207e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "path = path if drive is None else \"/content/drive/MyDrive/self-learn/unlearning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbbd3f0a-951f-442b-a838-82d0177bb616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from constants import *\n",
    "from utils import set_seed, train_data, val_data, train_loader, val_loader, fine_labels\n",
    "from models import get_model_and_optimizer\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f295fa22-3134-4c48-a717-106da164bb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: CNN_CIFAR_100_ORIGINAL\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = f\"CNN_CIFAR_100_ORIGINAL\"\n",
    "print(\"Model Name:\", MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbaed7e-f154-4f09-9dc7-23d984921c83",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "764328cc-4458-4879-9c19-88caad82698a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cloud'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_class = 23\n",
    "fine_labels[target_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78e85115-1540-438a-b44d-f02d47a979a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, val_loader, criterion, device):\n",
    "    val_losses = []\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (img, label) in enumerate(val_loader):\n",
    "\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            out = model(img)  # model returns activations as well\n",
    "            loss_eval = criterion(out, label)\n",
    "            val_losses.append(loss_eval.item())\n",
    "\n",
    "            pred = out.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "\n",
    "    val_loss = np.mean(val_losses)\n",
    "    val_acc = correct / ((len(val_loader) - 1) * BATCH_SIZE + label.size(0))\n",
    "\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a105a27-a151-42ca-83b7-4b681167763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "forget_idx = np.where(np.array(train_data.targets) == target_class)[0]\n",
    "forget_mask = np.zeros(len(train_data.targets), dtype=bool)\n",
    "forget_mask[forget_idx] = True\n",
    "retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
    "\n",
    "forget_data = torch.utils.data.Subset(train_data, forget_idx)\n",
    "retain_data = torch.utils.data.Subset(train_data, retain_idx)\n",
    "\n",
    "forget_loader = torch.utils.data.DataLoader(\n",
    "    forget_data, batch_size=BATCH_SIZE, shuffle=False\n",
    ")\n",
    "retain_loader = torch.utils.data.DataLoader(\n",
    "    retain_data, batch_size=BATCH_SIZE, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3bf986-ce68-4ba8-a4a7-ee32546d2cc3",
   "metadata": {},
   "source": [
    "# JiT Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b3e3283-c099-49fd-a6a5-e4ec6561eba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO:\n",
    "\n",
    "# Create randomly perturbed variants of forget set via additive noise\n",
    "# Train model to minimize output distance between original forget set and this perturbed set\n",
    "\n",
    "# constants TO USE: JIT_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f240999-ac41-48ac-a444-b505105ca0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise(object):\n",
    "    def __init__(self, mean=0.0, std=1.0, device=\"cpu\"):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        _max = tensor.max()\n",
    "        _min = tensor.min()\n",
    "        tensor = (\n",
    "            tensor + torch.randn_like(tensor).to(self.device) * self.std + self.mean\n",
    "        )\n",
    "        tensor = torch.clamp(tensor, min=_min, max=_max)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d215358-c98d-451e-8d10-d35aec1018b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_fn = transforms.Compose(\n",
    "    [\n",
    "        GaussianNoise(0.0, SIGMA, device=device),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5955c397-68be-44b1-bf18-770a3017641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jit_train():\n",
    "\n",
    "    # for batch in forget_loader:\n",
    "    #     for _ in range(N_VARIANT):\n",
    "    #         # apply transform_fn\n",
    "    #         # pass to model via no.grad\n",
    "    #         # compute norms and loss\n",
    "    #     # normalize loss by N_VARIANT\n",
    "    #     loss.backward()\n",
    "    #     optimizer.step()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3def29fd-a3cb-48d5-adf9-70d3d3069d7c",
   "metadata": {},
   "source": [
    "# Driver code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f3835c3e-ee66-4c7f-be88-be568f544412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher model loaded\n"
     ]
    }
   ],
   "source": [
    "LOAD_EPOCH = 100\n",
    "\n",
    "model, _ = get_model_and_optimizer()\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        f\"{path}/checkpoints/{MODEL_NAME}_EPOCH_{LOAD_EPOCH}_SEED_{SEED}.pt\",\n",
    "        map_location=device,\n",
    "    )[\"model_state_dict\"]\n",
    ")\n",
    "model.to(device)\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "21918ade-53eb-4a1d-b0d5-b46c00adf31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcc9157-19f3-4465-8e31-e48fb285a686",
   "metadata": {},
   "source": [
    "#### TODO: define JiT noise, perturbation, train functions, write driver code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf45401-2500-4c1b-bdde-ecb9dc62899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(\n",
    "#             {\n",
    "#                 \"model_state_dict\": model.state_dict(),\n",
    "#             },\n",
    "#             f\"{path}/checkpoints/{MODEL_NAME}_UNLEARNED_JIT.pt\"\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c500f2-98db-4407-8e55-e82782ae5788",
   "metadata": {},
   "source": [
    "## visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "51e852dd-9b41-4358-b2ad-fcf6307693ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use shuffle for more interesting results\n",
    "val_viz_loader = torch.utils.data.DataLoader(\n",
    "    val_data, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "forget_viz_loader = torch.utils.data.DataLoader(\n",
    "    forget_data, batch_size=BATCH_SIZE, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3798b0f4-55e1-47b0-967d-50331fd95616",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # choose one batch from val and one batch from forget\n",
    "    for (val_img, val_label), (forget_img, forget_label) in zip(\n",
    "        val_viz_loader, forget_viz_loader\n",
    "    ):\n",
    "        viz_img, viz_label = torch.cat([val_img, forget_img]), torch.cat(\n",
    "            [val_label, forget_label]\n",
    "        )\n",
    "        viz_img, viz_label = viz_img.to(device), viz_label.to(device)\n",
    "        out = model(viz_img)\n",
    "        pred = out.argmax(dim=-1)\n",
    "        break\n",
    "\n",
    "# assumes BATCH_SIZE=8\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16, 12))\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    ax.set_title(\n",
    "        f\"Pred: {fine_labels[pred[i]]} | Label: {fine_labels[viz_label[i]]}\", fontsize=8\n",
    "    )\n",
    "    ax.imshow(invTrans(viz_img[i]).cpu().permute(1, 2, 0))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
